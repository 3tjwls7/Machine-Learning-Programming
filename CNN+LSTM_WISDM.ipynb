{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 0) Imports\n",
        "# ================================================\n",
        "import os, re, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "GSSlCz6AekHu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 1) 데이터 로드 & 기본 전처리\n",
        "# ================================================\n",
        "cols = [\"subject\", \"label\", \"timestamp\", \"x\", \"y\", \"z\"]\n",
        "df = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/data/WISDM_ar_v1.1_raw.txt\",\n",
        "    header=None, names=cols, on_bad_lines=\"skip\"\n",
        ").dropna()\n",
        "\n",
        "df[\"z\"] = df[\"z\"].astype(str).str.replace(\";\", \"\", regex=False).astype(float)\n",
        "df[\"x\"] = df[\"x\"].astype(float)\n",
        "df[\"y\"] = df[\"y\"].astype(float)\n",
        "\n",
        "df[\"subject\"] = pd.to_numeric(df[\"subject\"], errors=\"coerce\").astype(\"Int64\")\n",
        "df[\"timestamp\"] = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\")\n",
        "for c in [\"x\",\"y\",\"z\"]:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "df = df.dropna().sort_values([\"subject\",\"label\",\"timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"샘플:\\n\", df.head(), \"\\n\")\n",
        "print(\"고유 subject:\", df[\"subject\"].nunique())\n",
        "print(\"라벨 분포:\", Counter(df[\"label\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_yOKN72enQ9",
        "outputId": "5041bfb3-056d-42e6-9c3b-cd11cf318cf4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플:\n",
            "    subject       label      timestamp     x      y     z\n",
            "0        1  Downstairs  6552942304000 -0.15   9.15 -0.34\n",
            "1        1  Downstairs  6552992292000  0.11   9.19  2.76\n",
            "2        1  Downstairs  6553042310000 -4.06   7.40  4.02\n",
            "3        1  Downstairs  6553092298000 -2.87   7.93  3.21\n",
            "4        1  Downstairs  6553142347000 -0.19  10.04  4.82 \n",
            "\n",
            "고유 subject: 36\n",
            "라벨 분포: Counter({'Walking': 418393, 'Jogging': 336445, 'Upstairs': 122869, 'Downstairs': 100425, 'Sitting': 59939, 'Standing': 48394})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 2) get_frames (문자 라벨 대응: np.unique로 최빈값)\n",
        "# ================================================\n",
        "Fs = 20\n",
        "frame_size = 200           # 200 timestep (10초 분량)\n",
        "hop_size   = frame_size//2 # 50% overlap = 100\n",
        "\n",
        "def get_frames(df, frame_size, hop_size):\n",
        "    N_FEATURES = 3\n",
        "    frames, labels = [], []\n",
        "    xv = df[\"x\"].to_numpy(); yv = df[\"y\"].to_numpy(); zv = df[\"z\"].to_numpy()\n",
        "    lv = df[\"label\"].to_numpy()\n",
        "    for i in range(0, len(df) - frame_size, hop_size):\n",
        "        x = xv[i:i+frame_size]; y = yv[i:i+frame_size]; z = zv[i:i+frame_size]\n",
        "        seg = lv[i:i+frame_size]\n",
        "        vals, counts = np.unique(seg, return_counts=True)\n",
        "        label = vals[np.argmax(counts)]\n",
        "        frames.append([x,y,z])\n",
        "        labels.append(label)\n",
        "    frames = np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n",
        "    labels = np.asarray(labels)\n",
        "    return frames, labels\n"
      ],
      "metadata": {
        "id": "0M-ebYoSeqZx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 3) 프레임 생성 + magnitude 채널 추가\n",
        "# ================================================\n",
        "X_raw, y_raw = get_frames(df, frame_size, hop_size)\n",
        "print(\"X_raw:\", X_raw.shape, \"라벨:\", Counter(y_raw))\n",
        "\n",
        "# magnitude 채널 추가\n",
        "mag = np.linalg.norm(X_raw, axis=2, keepdims=True) # (N,T,1)\n",
        "X_raw = np.concatenate([X_raw, mag], axis=2)       # (N,T,4)\n",
        "\n",
        "# 라벨 인코딩\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Classes:\", list(le.classes_))\n",
        "\n",
        "# train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_raw, y, test_size=0.2, random_state=SEED, stratify=y\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F7SnVexes2t",
        "outputId": "c9457ab8-c418-49b5-aad8-fde0008c61c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_raw: (10863, 200, 3) 라벨: Counter({np.str_('Walking'): 4185, np.str_('Jogging'): 3363, np.str_('Upstairs'): 1229, np.str_('Downstairs'): 1001, np.str_('Sitting'): 601, np.str_('Standing'): 484})\n",
            "Classes: [np.str_('Downstairs'), np.str_('Jogging'), np.str_('Sitting'), np.str_('Standing'), np.str_('Upstairs'), np.str_('Walking')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 4) 표준화 (Train 기준으로 fit)\n",
        "# ================================================\n",
        "scaler = StandardScaler()\n",
        "X_train_2d = X_train.reshape(-1, X_train.shape[-1])  # (N*T, 4)\n",
        "X_test_2d  = X_test.reshape(-1,  X_test.shape[-1])\n",
        "\n",
        "scaler.fit(X_train_2d)\n",
        "X_train = scaler.transform(X_train_2d).reshape(X_train.shape)\n",
        "X_test  = scaler.transform(X_test_2d ).reshape(X_test.shape)\n"
      ],
      "metadata": {
        "id": "FYpc8jbvewku"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 5) CNN + LSTM 모델 정의\n",
        "# ================================================\n",
        "def build_cnn_lstm(input_shape, num_classes):\n",
        "    inp = layers.Input(shape=input_shape)   # (T, 4)\n",
        "\n",
        "    # CNN 블록\n",
        "    x = layers.Conv1D(64, kernel_size=5, activation=\"relu\", padding=\"same\")(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv1D(128, kernel_size=5, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # LSTM 블록\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Dense 블록\n",
        "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_cnn_lstm((frame_size, 4), num_classes)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "18jwlcVseyrE",
        "outputId": "acb52636-b04e-4244-811d-1ead67acc302"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m1,344\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m41,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m263,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m774\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m488,006\u001b[0m (1.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">488,006</span> (1.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m487,622\u001b[0m (1.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">487,622</span> (1.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 6) class_weight 적용\n",
        "# ================================================\n",
        "cw = compute_class_weight(class_weight=\"balanced\",\n",
        "                          classes=np.unique(y_train),\n",
        "                          y=y_train)\n",
        "class_weight = {i: w for i, w in enumerate(cw)}\n",
        "print(\"class_weight:\", class_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mroy6yKfe2kr",
        "outputId": "b2a87d5f-d633-4049-c61e-12883b2e9917"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_weight: {0: np.float64(1.8081564710778193), 1: np.float64(0.5384138785625775), 2: np.float64(3.011088011088011), 3: np.float64(3.7424633936261844), 4: np.float64(1.4733808070532384), 5: np.float64(0.43259657506969335)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 7) 학습\n",
        "# ================================================\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=60,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weight,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld-LyTpqe4T5",
        "outputId": "c5be74b5-3d8c-4019-a646-819b014a0749"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - accuracy: 0.5341 - loss: 1.1445 - val_accuracy: 0.5138 - val_loss: 1.0975\n",
            "Epoch 2/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.7736 - loss: 0.5921 - val_accuracy: 0.3832 - val_loss: 1.7176\n",
            "Epoch 3/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8460 - loss: 0.4227 - val_accuracy: 0.3389 - val_loss: 1.8586\n",
            "Epoch 4/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9033 - loss: 0.3073 - val_accuracy: 0.4925 - val_loss: 1.1882\n",
            "Epoch 5/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9214 - loss: 0.2824 - val_accuracy: 0.6398 - val_loss: 0.9172\n",
            "Epoch 6/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9408 - loss: 0.2119 - val_accuracy: 0.7434 - val_loss: 0.6899\n",
            "Epoch 7/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9436 - loss: 0.1961 - val_accuracy: 0.8797 - val_loss: 0.3567\n",
            "Epoch 8/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9464 - loss: 0.1847 - val_accuracy: 0.9586 - val_loss: 0.1510\n",
            "Epoch 9/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9530 - loss: 0.1696 - val_accuracy: 0.9632 - val_loss: 0.1342\n",
            "Epoch 10/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9519 - loss: 0.1595 - val_accuracy: 0.9672 - val_loss: 0.1272\n",
            "Epoch 11/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9706 - loss: 0.1187 - val_accuracy: 0.9649 - val_loss: 0.1276\n",
            "Epoch 12/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9684 - loss: 0.1329 - val_accuracy: 0.9684 - val_loss: 0.1219\n",
            "Epoch 13/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9709 - loss: 0.1145 - val_accuracy: 0.9707 - val_loss: 0.1140\n",
            "Epoch 14/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1087 - val_accuracy: 0.9678 - val_loss: 0.1178\n",
            "Epoch 15/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9792 - loss: 0.0865 - val_accuracy: 0.9735 - val_loss: 0.1156\n",
            "Epoch 16/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9778 - loss: 0.0887 - val_accuracy: 0.9747 - val_loss: 0.0937\n",
            "Epoch 17/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9742 - loss: 0.0849 - val_accuracy: 0.9707 - val_loss: 0.1162\n",
            "Epoch 18/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9765 - loss: 0.0933 - val_accuracy: 0.9707 - val_loss: 0.1061\n",
            "Epoch 19/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9735 - loss: 0.1111 - val_accuracy: 0.9707 - val_loss: 0.1194\n",
            "Epoch 20/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9765 - loss: 0.0867 - val_accuracy: 0.9735 - val_loss: 0.1029\n",
            "Epoch 21/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9824 - loss: 0.0780 - val_accuracy: 0.9776 - val_loss: 0.1000\n",
            "Epoch 22/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9778 - loss: 0.0847 - val_accuracy: 0.9718 - val_loss: 0.1174\n",
            "Epoch 23/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9829 - loss: 0.0784 - val_accuracy: 0.9793 - val_loss: 0.0935\n",
            "Epoch 24/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9787 - loss: 0.0815 - val_accuracy: 0.9712 - val_loss: 0.1257\n",
            "Epoch 25/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9828 - loss: 0.0652 - val_accuracy: 0.9810 - val_loss: 0.0810\n",
            "Epoch 26/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9839 - loss: 0.0543 - val_accuracy: 0.9747 - val_loss: 0.1228\n",
            "Epoch 27/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9874 - loss: 0.0591 - val_accuracy: 0.9643 - val_loss: 0.1668\n",
            "Epoch 28/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9817 - loss: 0.0837 - val_accuracy: 0.9810 - val_loss: 0.0837\n",
            "Epoch 29/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9898 - loss: 0.0469 - val_accuracy: 0.9822 - val_loss: 0.0801\n",
            "Epoch 30/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9886 - loss: 0.0484 - val_accuracy: 0.9747 - val_loss: 0.1195\n",
            "Epoch 31/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9888 - loss: 0.0577 - val_accuracy: 0.9770 - val_loss: 0.1222\n",
            "Epoch 32/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9818 - loss: 0.0770 - val_accuracy: 0.9839 - val_loss: 0.0701\n",
            "Epoch 33/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0518 - val_accuracy: 0.9776 - val_loss: 0.1018\n",
            "Epoch 34/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9892 - loss: 0.0415 - val_accuracy: 0.9816 - val_loss: 0.0983\n",
            "Epoch 35/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9929 - loss: 0.0355 - val_accuracy: 0.9804 - val_loss: 0.0974\n",
            "Epoch 36/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9957 - loss: 0.0278 - val_accuracy: 0.9758 - val_loss: 0.1117\n",
            "Epoch 37/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9901 - loss: 0.0641 - val_accuracy: 0.9833 - val_loss: 0.0857\n",
            "Epoch 38/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9930 - loss: 0.0375 - val_accuracy: 0.9822 - val_loss: 0.0826\n",
            "Epoch 39/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9911 - loss: 0.0335 - val_accuracy: 0.9787 - val_loss: 0.0933\n",
            "Epoch 40/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9924 - loss: 0.0341 - val_accuracy: 0.9799 - val_loss: 0.1060\n",
            "Epoch 41/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9887 - loss: 0.0524 - val_accuracy: 0.9741 - val_loss: 0.1276\n",
            "Epoch 42/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9893 - loss: 0.0488 - val_accuracy: 0.9845 - val_loss: 0.0955\n",
            "Epoch 43/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9945 - loss: 0.0262 - val_accuracy: 0.9833 - val_loss: 0.0811\n",
            "Epoch 44/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9907 - loss: 0.0350 - val_accuracy: 0.9753 - val_loss: 0.1063\n",
            "Epoch 45/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9911 - loss: 0.0399 - val_accuracy: 0.9822 - val_loss: 0.0928\n",
            "Epoch 46/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9926 - loss: 0.0322 - val_accuracy: 0.9816 - val_loss: 0.0872\n",
            "Epoch 47/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9918 - loss: 0.0311 - val_accuracy: 0.9856 - val_loss: 0.0886\n",
            "Epoch 48/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9964 - loss: 0.0217 - val_accuracy: 0.9833 - val_loss: 0.0942\n",
            "Epoch 49/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9959 - loss: 0.0230 - val_accuracy: 0.9793 - val_loss: 0.1065\n",
            "Epoch 50/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9934 - loss: 0.0426 - val_accuracy: 0.9787 - val_loss: 0.1012\n",
            "Epoch 51/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9926 - loss: 0.0342 - val_accuracy: 0.9839 - val_loss: 0.0803\n",
            "Epoch 52/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9969 - loss: 0.0216 - val_accuracy: 0.9839 - val_loss: 0.0903\n",
            "Epoch 53/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9948 - loss: 0.0260 - val_accuracy: 0.9822 - val_loss: 0.1113\n",
            "Epoch 54/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9931 - loss: 0.0397 - val_accuracy: 0.9856 - val_loss: 0.0860\n",
            "Epoch 55/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9940 - loss: 0.0234 - val_accuracy: 0.9816 - val_loss: 0.0982\n",
            "Epoch 56/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9964 - loss: 0.0189 - val_accuracy: 0.9810 - val_loss: 0.0973\n",
            "Epoch 57/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9960 - loss: 0.0188 - val_accuracy: 0.9845 - val_loss: 0.0768\n",
            "Epoch 58/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9975 - loss: 0.0173 - val_accuracy: 0.9724 - val_loss: 0.1308\n",
            "Epoch 59/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9903 - loss: 0.0291 - val_accuracy: 0.9200 - val_loss: 0.3231\n",
            "Epoch 60/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9864 - loss: 0.0533 - val_accuracy: 0.9799 - val_loss: 0.0986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 8) 평가\n",
        "# ================================================\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"[Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report(y_test, y_pred, target_names=list(le.classes_)))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix (rows=true, cols=pred):\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqvvj-6Me793",
        "outputId": "aab438a7-f894-4609-e1a0-ba04e60dfb4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Test] loss=0.0872  acc=0.9811\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Downstairs       0.93      0.99      0.96       200\n",
            "     Jogging       0.99      0.99      0.99       673\n",
            "     Sitting       0.99      0.99      0.99       120\n",
            "    Standing       0.99      0.98      0.98        97\n",
            "    Upstairs       0.97      0.91      0.94       246\n",
            "     Walking       0.99      0.99      0.99       837\n",
            "\n",
            "    accuracy                           0.98      2173\n",
            "   macro avg       0.98      0.98      0.98      2173\n",
            "weighted avg       0.98      0.98      0.98      2173\n",
            "\n",
            "\n",
            "Confusion Matrix (rows=true, cols=pred):\n",
            " [[198   0   0   0   0   2]\n",
            " [  4 666   0   0   3   0]\n",
            " [  0   0 119   1   0   0]\n",
            " [  0   0   1  95   1   0]\n",
            " [  9   3   0   0 225   9]\n",
            " [  3   1   0   0   4 829]]\n"
          ]
        }
      ]
    }
  ]
}