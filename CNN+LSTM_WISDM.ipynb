{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 0) Imports\n",
        "# ================================================\n",
        "import os, re, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "GSSlCz6AekHu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 1) 데이터 로드 & 기본 전처리\n",
        "# ================================================\n",
        "cols = [\"subject\", \"label\", \"timestamp\", \"x\", \"y\", \"z\"]\n",
        "df = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/data/WISDM_ar_v1.1_raw.txt\",\n",
        "    header=None, names=cols, on_bad_lines=\"skip\"\n",
        ").dropna()\n",
        "\n",
        "df[\"z\"] = df[\"z\"].astype(str).str.replace(\";\", \"\", regex=False).astype(float)\n",
        "df[\"x\"] = df[\"x\"].astype(float)\n",
        "df[\"y\"] = df[\"y\"].astype(float)\n",
        "\n",
        "df[\"subject\"] = pd.to_numeric(df[\"subject\"], errors=\"coerce\").astype(\"Int64\")\n",
        "df[\"timestamp\"] = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\")\n",
        "for c in [\"x\",\"y\",\"z\"]:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "df = df.dropna().sort_values([\"subject\",\"label\",\"timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"샘플:\\n\", df.head(), \"\\n\")\n",
        "print(\"고유 subject:\", df[\"subject\"].nunique())\n",
        "print(\"라벨 분포:\", Counter(df[\"label\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_yOKN72enQ9",
        "outputId": "e1cbd5a9-06f7-4aa2-a6ca-9ae33dc016d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플:\n",
            "    subject       label      timestamp     x      y     z\n",
            "0        1  Downstairs  6552942304000 -0.15   9.15 -0.34\n",
            "1        1  Downstairs  6552992292000  0.11   9.19  2.76\n",
            "2        1  Downstairs  6553042310000 -4.06   7.40  4.02\n",
            "3        1  Downstairs  6553092298000 -2.87   7.93  3.21\n",
            "4        1  Downstairs  6553142347000 -0.19  10.04  4.82 \n",
            "\n",
            "고유 subject: 36\n",
            "라벨 분포: Counter({'Walking': 418393, 'Jogging': 336445, 'Upstairs': 122869, 'Downstairs': 100425, 'Sitting': 59939, 'Standing': 48394})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 2) get_frames (문자 라벨 대응: np.unique로 최빈값)\n",
        "# ================================================\n",
        "Fs = 20\n",
        "frame_size = 200           # 200 timestep (10초 분량)\n",
        "hop_size   = frame_size//2 # 50% overlap = 100\n",
        "\n",
        "def get_frames(df, frame_size, hop_size):\n",
        "    N_FEATURES = 3\n",
        "    frames, labels = [], []\n",
        "    xv = df[\"x\"].to_numpy(); yv = df[\"y\"].to_numpy(); zv = df[\"z\"].to_numpy()\n",
        "    lv = df[\"label\"].to_numpy()\n",
        "    for i in range(0, len(df) - frame_size, hop_size):\n",
        "        x = xv[i:i+frame_size]; y = yv[i:i+frame_size]; z = zv[i:i+frame_size]\n",
        "        seg = lv[i:i+frame_size]\n",
        "        vals, counts = np.unique(seg, return_counts=True)\n",
        "        label = vals[np.argmax(counts)]\n",
        "        frames.append([x,y,z])\n",
        "        labels.append(label)\n",
        "    frames = np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n",
        "    labels = np.asarray(labels)\n",
        "    return frames, labels\n"
      ],
      "metadata": {
        "id": "0M-ebYoSeqZx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 2-1) Subject-wise wrapper\n",
        "# ================================================\n",
        "def run_subjectwise(get_frames_func, df, group_col, frame_size, hop_size):\n",
        "    X_list, y_list = [], []\n",
        "    for _, g in df.groupby(group_col, sort=False):\n",
        "        # 이미 위에서 timestamp 정렬했지만 안전하게 한 번 더 보장하려면 주석 해제\n",
        "        # g = g.sort_values(\"timestamp\")\n",
        "        Xg, yg = get_frames_func(g, frame_size, hop_size)\n",
        "        if len(yg) == 0:\n",
        "            continue\n",
        "        X_list.append(Xg)\n",
        "        y_list.append(yg)\n",
        "    if not X_list:\n",
        "        return np.empty((0, frame_size, N_FEATURES)), np.array([])\n",
        "    return np.vstack(X_list), np.concatenate(y_list)"
      ],
      "metadata": {
        "id": "-tlv1cy7Dz3L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 3) Subject-wise Train/Test Split\n",
        "#    예: subject <= 30 → train, >30 → test\n",
        "# ================================================\n",
        "df_train = df[df[\"subject\"] <= 30].copy()\n",
        "df_test  = df[df[\"subject\"] >  30].copy()\n",
        "\n",
        "X_train_raw, y_train_raw = run_subjectwise(get_frames, df_train, \"subject\", frame_size, hop_size)\n",
        "X_test_raw,  y_test_raw  = run_subjectwise(get_frames, df_test,  \"subject\", frame_size, hop_size)\n",
        "\n",
        "print(\"X_train_raw:\", X_train_raw.shape, \" / X_test_raw:\", X_test_raw.shape)\n",
        "print(\"Train 라벨 분포:\", Counter(y_train_raw))\n",
        "print(\"Test  라벨 분포:\", Counter(y_test_raw))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F7SnVexes2t",
        "outputId": "74610477-9c3e-467a-8c55-be50a1240411"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_raw: (8821, 200, 3)  / X_test_raw: (1989, 200, 3)\n",
            "Train 라벨 분포: Counter({np.str_('Walking'): 3446, np.str_('Jogging'): 2696, np.str_('Upstairs'): 1027, np.str_('Downstairs'): 812, np.str_('Sitting'): 457, np.str_('Standing'): 383})\n",
            "Test  라벨 분포: Counter({np.str_('Walking'): 702, np.str_('Jogging'): 667, np.str_('Upstairs'): 200, np.str_('Downstairs'): 175, np.str_('Sitting'): 143, np.str_('Standing'): 102})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 3-1) magnitude 채널 추가 (각 세트별로)\n",
        "# ================================================\n",
        "def add_magnitude_channel(X):\n",
        "    # X: (N,T,3) -> cat ||v||: (N,T,1) -> (N,T,4)\n",
        "    mag = np.linalg.norm(X, axis=2, keepdims=True)\n",
        "    return np.concatenate([X, mag], axis=2)\n",
        "\n",
        "X_train_raw = add_magnitude_channel(X_train_raw)   # (N,T,4)\n",
        "X_test_raw  = add_magnitude_channel(X_test_raw)    # (N,T,4)"
      ],
      "metadata": {
        "id": "9ZwdP-p9Ez9n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 3-2) 라벨 인코딩 (정수)\n",
        "# ================================================\n",
        "le = LabelEncoder()\n",
        "le.fit(df[\"label\"])\n",
        "y_train = le.transform(y_train_raw)\n",
        "y_test  = le.transform(y_test_raw)\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Classes:\", list(le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LyxyyE-E1yP",
        "outputId": "ff6429a4-37c6-4a18-fc6d-b97b52089b23"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs', 'Walking']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 4) 표준화 (Train 기준으로 fit → Train/Test transform)\n",
        "#     채널별 정규화: (N*T, C)\n",
        "# ================================================\n",
        "scaler = StandardScaler()\n",
        "X_train_2d = X_train_raw.reshape(-1, X_train_raw.shape[-1])  # (N*T, 4)\n",
        "X_test_2d  = X_test_raw.reshape(-1,  X_test_raw.shape[-1])\n",
        "\n",
        "scaler.fit(X_train_2d)\n",
        "X_train = scaler.transform(X_train_2d).reshape(X_train_raw.shape)\n",
        "X_test  = scaler.transform(X_test_2d ).reshape(X_test_raw.shape)\n",
        "\n",
        "print(\"Shapes ->\",\n",
        "      \"X_train:\", X_train.shape,\n",
        "      \"X_test:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "FYpc8jbvewku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e8f70f-ec62-4127-b783-d45d28c9f86b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes -> X_train: (8821, 200, 4) X_test: (1989, 200, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 5) CNN + BiLSTM 모델 정의\n",
        "# ================================================\n",
        "def build_cnn_lstm(input_shape, num_classes):\n",
        "    inp = layers.Input(shape=input_shape)   # (T, 4)\n",
        "\n",
        "    # CNN block\n",
        "    x = layers.Conv1D(64, kernel_size=5, activation=\"relu\", padding=\"same\")(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv1D(128, kernel_size=5, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # BiLSTM block\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Dense block\n",
        "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "        loss=\"sparse_categorical_crossentropy\",  # 정수 라벨\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_cnn_lstm((frame_size, 4), num_classes)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "18jwlcVseyrE",
        "outputId": "3455a5d5-d762-40c8-ab5c-6753098a3985"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m1,344\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m41,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m263,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m774\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m488,006\u001b[0m (1.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">488,006</span> (1.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m487,622\u001b[0m (1.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">487,622</span> (1.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 6) class_weight (Train 분포로 계산)\n",
        "# ================================================\n",
        "cw = compute_class_weight(class_weight=\"balanced\",\n",
        "                          classes=np.unique(y_train),\n",
        "                          y=y_train)\n",
        "class_weight = {i: w for i, w in enumerate(cw)}\n",
        "print(\"class_weight:\", class_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mroy6yKfe2kr",
        "outputId": "e5abf37f-059f-43fe-b60c-303722e2536b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_weight: {0: np.float64(1.8105500821018063), 1: np.float64(0.5453140454995055), 2: np.float64(3.2169948942377826), 3: np.float64(3.838555265448216), 4: np.float64(1.4315157416423239), 5: np.float64(0.4266299090733217)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 7) 학습\n",
        "#   주의: validation_split=0.2는 같은 subject의 윈도우가\n",
        "#   train/val에 섞일 수 있음(빠른 확인용).\n",
        "#   더 엄밀히 하려면 train subject 중 일부를 검증 전용 subject로 분리하세요.\n",
        "# ================================================\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=60,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weight,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld-LyTpqe4T5",
        "outputId": "2636278c-e33f-448c-968e-f2d158efd2b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.5583 - loss: 1.0851 - val_accuracy: 0.4113 - val_loss: 1.1479\n",
            "Epoch 2/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7947 - loss: 0.5171 - val_accuracy: 0.3003 - val_loss: 2.1735\n",
            "Epoch 3/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8963 - loss: 0.2965 - val_accuracy: 0.2686 - val_loss: 2.2780\n",
            "Epoch 4/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9280 - loss: 0.2349 - val_accuracy: 0.3892 - val_loss: 2.0087\n",
            "Epoch 5/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9496 - loss: 0.1775 - val_accuracy: 0.4125 - val_loss: 1.9518\n",
            "Epoch 6/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9559 - loss: 0.1506 - val_accuracy: 0.5224 - val_loss: 1.9055\n",
            "Epoch 7/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9616 - loss: 0.1404 - val_accuracy: 0.7031 - val_loss: 1.0306\n",
            "Epoch 8/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9664 - loss: 0.1197 - val_accuracy: 0.7496 - val_loss: 1.0485\n",
            "Epoch 9/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9726 - loss: 0.1083 - val_accuracy: 0.7473 - val_loss: 1.0848\n",
            "Epoch 10/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9715 - loss: 0.1030 - val_accuracy: 0.7473 - val_loss: 1.1279\n",
            "Epoch 11/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9755 - loss: 0.0893 - val_accuracy: 0.7694 - val_loss: 1.0794\n",
            "Epoch 12/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9755 - loss: 0.0877 - val_accuracy: 0.8119 - val_loss: 0.9326\n",
            "Epoch 13/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9816 - loss: 0.0859 - val_accuracy: 0.8408 - val_loss: 0.8221\n",
            "Epoch 14/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9843 - loss: 0.0672 - val_accuracy: 0.8204 - val_loss: 0.8929\n",
            "Epoch 15/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9828 - loss: 0.0691 - val_accuracy: 0.8266 - val_loss: 0.9357\n",
            "Epoch 16/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9870 - loss: 0.0624 - val_accuracy: 0.8266 - val_loss: 1.0016\n",
            "Epoch 17/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9833 - loss: 0.0679 - val_accuracy: 0.8595 - val_loss: 0.8288\n",
            "Epoch 18/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9894 - loss: 0.0640 - val_accuracy: 0.8351 - val_loss: 0.8798\n",
            "Epoch 19/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9888 - loss: 0.0585 - val_accuracy: 0.8198 - val_loss: 0.9734\n",
            "Epoch 20/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9908 - loss: 0.0452 - val_accuracy: 0.8159 - val_loss: 0.9892\n",
            "Epoch 21/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9917 - loss: 0.0406 - val_accuracy: 0.8187 - val_loss: 0.9764\n",
            "Epoch 22/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9913 - loss: 0.0475 - val_accuracy: 0.8119 - val_loss: 1.0142\n",
            "Epoch 23/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9907 - loss: 0.0428 - val_accuracy: 0.8176 - val_loss: 1.0224\n",
            "Epoch 24/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9852 - loss: 0.0664 - val_accuracy: 0.8193 - val_loss: 0.9747\n",
            "Epoch 25/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9836 - loss: 0.0681 - val_accuracy: 0.8544 - val_loss: 0.9110\n",
            "Epoch 26/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0610 - val_accuracy: 0.8589 - val_loss: 0.7653\n",
            "Epoch 27/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9941 - loss: 0.0361 - val_accuracy: 0.8459 - val_loss: 0.8290\n",
            "Epoch 28/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9920 - loss: 0.0454 - val_accuracy: 0.8221 - val_loss: 0.9686\n",
            "Epoch 29/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9909 - loss: 0.0363 - val_accuracy: 0.7977 - val_loss: 1.1215\n",
            "Epoch 30/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9956 - loss: 0.0322 - val_accuracy: 0.8227 - val_loss: 1.0793\n",
            "Epoch 31/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9927 - loss: 0.0374 - val_accuracy: 0.8601 - val_loss: 0.9426\n",
            "Epoch 32/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9955 - loss: 0.0259 - val_accuracy: 0.8686 - val_loss: 1.0065\n",
            "Epoch 33/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9966 - loss: 0.0278 - val_accuracy: 0.8380 - val_loss: 1.0025\n",
            "Epoch 34/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0240 - val_accuracy: 0.8431 - val_loss: 0.8693\n",
            "Epoch 35/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9972 - loss: 0.0220 - val_accuracy: 0.8618 - val_loss: 0.8622\n",
            "Epoch 36/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9908 - loss: 0.0404 - val_accuracy: 0.8113 - val_loss: 1.1517\n",
            "Epoch 37/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9865 - loss: 0.0793 - val_accuracy: 0.8085 - val_loss: 1.1355\n",
            "Epoch 38/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9911 - loss: 0.0489 - val_accuracy: 0.8210 - val_loss: 1.1171\n",
            "Epoch 39/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9953 - loss: 0.0284 - val_accuracy: 0.8062 - val_loss: 1.1258\n",
            "Epoch 40/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9949 - loss: 0.0272 - val_accuracy: 0.8380 - val_loss: 0.9730\n",
            "Epoch 41/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9960 - loss: 0.0248 - val_accuracy: 0.7932 - val_loss: 1.1276\n",
            "Epoch 42/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9891 - loss: 0.0358 - val_accuracy: 0.7926 - val_loss: 1.0810\n",
            "Epoch 43/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9937 - loss: 0.0290 - val_accuracy: 0.8227 - val_loss: 1.1674\n",
            "Epoch 44/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9975 - loss: 0.0202 - val_accuracy: 0.8346 - val_loss: 1.0799\n",
            "Epoch 45/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9948 - loss: 0.0298 - val_accuracy: 0.8170 - val_loss: 1.0439\n",
            "Epoch 46/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9959 - loss: 0.0264 - val_accuracy: 0.8221 - val_loss: 0.9628\n",
            "Epoch 47/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9927 - loss: 0.0303 - val_accuracy: 0.8663 - val_loss: 0.8011\n",
            "Epoch 48/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9975 - loss: 0.0176 - val_accuracy: 0.7909 - val_loss: 1.1600\n",
            "Epoch 49/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9926 - loss: 0.0379 - val_accuracy: 0.8391 - val_loss: 0.9270\n",
            "Epoch 50/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9937 - loss: 0.0294 - val_accuracy: 0.8459 - val_loss: 0.9854\n",
            "Epoch 51/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9963 - loss: 0.0199 - val_accuracy: 0.8618 - val_loss: 0.9500\n",
            "Epoch 52/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9978 - loss: 0.0146 - val_accuracy: 0.8663 - val_loss: 0.9850\n",
            "Epoch 53/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9964 - loss: 0.0170 - val_accuracy: 0.8459 - val_loss: 0.9167\n",
            "Epoch 54/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9979 - loss: 0.0132 - val_accuracy: 0.8612 - val_loss: 0.9127\n",
            "Epoch 55/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9990 - loss: 0.0104 - val_accuracy: 0.8629 - val_loss: 0.8673\n",
            "Epoch 56/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9982 - loss: 0.0122 - val_accuracy: 0.8606 - val_loss: 0.9250\n",
            "Epoch 57/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0171 - val_accuracy: 0.8589 - val_loss: 0.9213\n",
            "Epoch 58/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9915 - loss: 0.0449 - val_accuracy: 0.7926 - val_loss: 1.1229\n",
            "Epoch 59/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9951 - loss: 0.0289 - val_accuracy: 0.7626 - val_loss: 1.5235\n",
            "Epoch 60/60\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9613 - loss: 0.1406 - val_accuracy: 0.8289 - val_loss: 0.8938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 8) 평가\n",
        "# ================================================\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"[Subject-wise Test] loss={test_loss:.4f}  acc={test_acc:.4f}\")\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
        "\n",
        "print(\"\\nClassification Report (Subject-wise)\")\n",
        "print(classification_report(y_test, y_pred, target_names=list(le.classes_)))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix (rows=true, cols=pred):\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqvvj-6Me793",
        "outputId": "668df189-da85-420e-c032-42c3a36bcab5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Subject-wise Test] loss=0.4500  acc=0.9140\n",
            "\n",
            "Classification Report (Subject-wise)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Downstairs       0.67      0.92      0.78       175\n",
            "     Jogging       1.00      0.96      0.98       667\n",
            "     Sitting       0.75      0.99      0.86       143\n",
            "    Standing       0.98      0.57      0.72       102\n",
            "    Upstairs       0.91      0.88      0.89       200\n",
            "     Walking       0.96      0.91      0.94       702\n",
            "\n",
            "    accuracy                           0.91      1989\n",
            "   macro avg       0.88      0.87      0.86      1989\n",
            "weighted avg       0.93      0.91      0.92      1989\n",
            "\n",
            "\n",
            "Confusion Matrix (rows=true, cols=pred):\n",
            " [[161   1   0   0   8   5]\n",
            " [  5 642   2   0   0  18]\n",
            " [  0   0 142   1   0   0]\n",
            " [  0   0  44  58   0   0]\n",
            " [ 21   0   1   0 175   3]\n",
            " [ 53   0   0   0   9 640]]\n"
          ]
        }
      ]
    }
  ]
}